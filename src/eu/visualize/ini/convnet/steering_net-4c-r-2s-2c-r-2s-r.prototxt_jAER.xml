<?xml version="1.0" encoding="utf-8"?>
<Network>
<name>steering_net-4c-r-2s-2c-r-2s-r</name>
<type>caffe_net</type>
<notes>Built using cnn_to_xml.py Authors: federico.corradi@inilabs.com, diederikmoeys@live.com</notes>
<nLayers>9</nLayers>
<dob>17/02/2016 16:43:37</dob>
	<Layer>
		<index>0</index>
		<type>i</type>
		<dimx>36</dimx>
		<dimy>36</dimy>
		<nUnits>1296</nUnits>
	</Layer>
	<Layer>
		<index>1</index>
		<type>c</type>
		<inputMaps>1</inputMaps>
		<outputMaps>4</outputMaps>
		<kernelSize>5</kernelSize>
		<activationFunction>relu</activationFunction>
		<biases dt="ASCII-float32">0.404474 -0.333187 1.32412 0.266078</biases>
		<kernels dt="ASCII-float32">-0.0127262 -0.473018 0.775386 -1.11377 0.535052 0.0923863 -0.166008 -0.224881 0.663724 -0.572301 -0.261673 0.361581 -0.244297 0.106954 -0.0852131 0.240464 -0.408782 -0.145137 0.464963 -0.326732 0.0821966 -0.261277 -0.384405 0.693842 -0.384097 -0.317803 0.21713 0.172057 -0.00177847 0.0618236 -0.0860646 0.228909 -0.602045 0.618105 -0.0193222 0.162553 -0.290051 0.664502 -0.365774 0.114932 -0.0821966 0.12617 0.327237 -0.189329 0.0675144 0.0546323 -0.124579 -0.930961 1.16828 -0.0582238 0.198719 0.00759827 -0.300338 -0.122318 0.313943 -0.223889 -0.0410876 -0.240053 -0.272912 0.0707698 -0.152649 -0.13324 -0.0637972 -0.551014 -0.0974153 0.162762 -0.425939 0.0175632 -0.481656 -0.0233993 -0.0793353 0.181794 -0.339593 -0.170147 0.0937917 -0.234824 0.023502 0.209297 -0.0455192 -0.0776898 -0.160148 0.127184 0.183235 -0.368266 0.172794 0.0423511 -0.120442 -0.108003 0.0698686 0.0356023 -0.17613 0.438224 -0.344381 -0.9173 0.826391 0.00388308 -0.43019 0.13189 1.05405 -0.929184</kernels>
	</Layer>
	<Layer>
		<index>2</index>
		<type>s</type>
		<poolingType>max</poolingType>
		<averageOver dt="ASCII-float32">2</averageOver>
		<strides>2</strides>
		<pad>0</pad>
	</Layer>
	<Layer>
		<index>3</index>
		<type>c</type>
		<inputMaps>4</inputMaps>
		<outputMaps>2</outputMaps>
		<kernelSize>5</kernelSize>
		<activationFunction>relu</activationFunction>
		<biases dt="ASCII-float32">0.340832 -0.0507477</biases>
		<kernels dt="ASCII-float32">-0.0652347 -0.183927 -0.191105 -0.170595 -0.155491 -0.0090278 -0.148898 -0.166416 -0.142313 -0.133913 0.0102943 -0.0572235 -0.107126 -0.153026 -0.224036 0.0441403 -0.112541 -0.0612369 -0.102159 -0.302288 -0.0816068 -0.0836768 -0.0702274 -0.0867895 -0.2997 0.571234 0.707696 0.513256 0.213754 -0.118349 0.373783 0.449932 0.403949 0.256627 -0.0854911 0.110076 0.0969757 0.105828 0.224969 -0.20933 0.277017 0.2242 0.139516 0.368466 0.0318588 0.305655 0.250163 0.250345 0.411719 0.00138115 0.0379254 0.0834535 0.0403089 0.215208 0.0701208 0.01217 -0.0300953 0.0104175 0.397663 0.0530463 -0.0892639 -0.037984 0.0754314 0.355318 0.246865 -0.114348 0.0104212 0.10251 0.276794 0.307489 -0.133508 -0.077037 0.0287757 0.236013 0.203446 0.191587 0.48756 0.384141 0.0887319 -0.0980057 0.0552532 0.402605 0.498794 0.231851 -0.157893 -0.147634 0.167399 0.405479 0.102328 -0.0594368 -0.0409747 0.459707 0.532025 0.223023 0.050087 0.0870562 0.689685 0.656386 0.0549085 -0.00497954 0.328116 0.196207 0.123744 -0.0217417 -0.333022 0.399263 0.406261 0.459528 0.106708 -0.102098 0.170238 0.215636 0.204651 0.122259 -0.157383 0.242024 0.166563 0.0588842 -0.117079 -0.25596 0.255332 0.210349 0.12577 -0.0271945 -0.119272 -0.0966965 -0.0213509 0.225491 0.017601 -0.131977 -0.0780095 -0.0674436 0.296452 0.148106 -0.0754096 -0.336124 0.0650627 0.351752 0.241745 -0.0590842 -0.262508 0.0177574 0.236888 0.16437 -0.0253015 -0.156114 0.0852586 0.224627 0.24868 0.0267557 0.205406 0.141637 0.0338153 -0.082329 -0.115632 0.0912764 0.104626 0.0462148 -0.0273837 -0.16072 0.0392603 0.146385 0.120712 0.000159318 -0.132535 0.141656 0.0399249 0.15489 -0.0254657 -0.16705 0.113857 -0.0285703 0.0792237 -0.123674 -0.174811 0.40013 0.438069 -0.063699 -0.0160361 0.108832 0.336327 0.639847 0.0497449 0.0148084 0.0882879 0.283343 0.344449 -0.0346165 -0.0213786 0.0443404 0.320078 0.678365 0.0133751 0.155217 -0.00808038 0.49223 0.913829 0.235253 0.218282 -0.0205786</kernels>
	</Layer>
	<Layer>
		<index>4</index>
		<type>s</type>
		<poolingType>max</poolingType>
		<averageOver dt="ASCII-float32">2</averageOver>
		<strides>2</strides>
		<pad>0</pad>
	</Layer>
	<Layer>
		<activationFunction>relu</activationFunction>
		<index>5</index>
		<type>o</type>
		<biases dt="ASCII-float32">-0.292475 -0.203076 -0.0177212 1.40202</biases>
		<weights cols="4" dt="ASCII-float32" rows="72">-0.294895 0.105788 -0.0426349 0.0681401 0.0445306 0.0788027 0.102531 -0.0487527 -0.0900538 -0.0157652 0.0488134 0.114717 0.0663967 0.170239 -0.207254 -0.123056 -0.0629809 0.000776861 -0.0124041 -0.0782434 0.206003 -0.31128 -0.0850599 0.111028 -0.0948865 -0.178707 -0.157536 0.187652 -0.0389673 -0.146235 0.0580844 0.289545 -0.119965 -0.20139 0.146286 0.226828 0.152113 -0.126993 -0.120933 0.29052 -0.137424 -0.0537971 -0.19429 0.155182 0.038305 -0.129313 -0.162939 0.372427 -0.244355 -0.119358 0.0856393 -0.00423815 -0.109369 -0.0454215 0.139244 0.25445 0.0997491 -0.165024 0.0711878 0.204744 0.210856 -0.250149 0.0669309 0.0539448 0.243516 -0.185768 -0.00278537 0.256825 0.251494 0.120353 -0.185691 0.230426 -0.347682 0.171557 0.00694552 0.303732 -0.118322 -0.0173019 -0.110811 0.29314 -0.162783 -0.0453635 0.0260785 0.118121 0.0409398 -0.104457 0.13701 0.105167 -0.0784308 -0.0296007 -0.0667048 0.249858 0.286474 -0.194499 -0.284049 0.362215 -0.275165 -0.115168 0.0917927 0.275859 -0.0169189 -0.00774471 -0.0707897 0.147246 0.116402 -0.195492 0.0724683 0.0394047 -0.0845863 0.098238 -0.0243051 0.237486 0.137504 -0.0570352 0.060371 0.115671 0.0260979 -0.116519 -0.0874194 0.24823 -0.108477 -0.468786 -0.0531968 0.353861 -0.121952 -0.060113 -0.123738 0.189754 -0.12003 -0.0648571 0.0699968 0.155015 -0.157566 -0.0448071 -0.00859251 0.233092 -0.0341133 -0.164817 -0.124328 0.0802667 -0.0345777 -0.0864535 -0.0282652 0.205058 -0.190102 0.338048 0.213861 0.195557 0.0450689 0.00449916 0.217242 0.101394 0.105097 -0.00897885 0.204225 0.244904 0.0342738 0.053698 0.193808 0.281718 0.118417 -0.147716 0.0474564 0.229363 0.131859 -0.0240121 -0.245627 0.238784 0.691729 -0.108244 -0.195679 0.065266 0.310092 0.108629 0.0557594 0.0594345 -0.0452683 0.681596 -0.052387 -0.284011 -0.185441 0.776457 -0.312564 -0.471106 -0.128336 0.299647 0.0383743 -0.227344 -0.632354 -0.140162 1.47978 -0.854538 1.10111 -0.0332774 -0.507367 -0.48225 0.0947158 0.136594 -0.00760463 -0.103804 -0.197022 0.307498 0.0595719 -0.125793 0.174312 0.257369 -0.0364709 -0.0445276 0.222696 0.150727 -0.426551 0.124719 -0.136548 -0.314246 0.741673 -0.059172 0.613209 -0.198303 0.00193726 -0.10918 -0.424082 0.225214 0.0777606 0.347151 -0.0338552 -0.045842 0.267004 0.222479 -0.0119004 0.0389395 0.0655245 -0.0421668 0.0890257 0.217115 -0.101628 0.204241 -0.228601 -0.0272762 0.0680145 5.30214e-05 0.1793 -0.0233131 0.0176366 -0.259439 0.0302717 0.0388501 0.0312507 -0.0636389 0.0361542 0.165237 -0.0726618 -0.00492008 -0.0253646 0.0558142 0.0748518 -0.106435 0.0746818 0.128963 0.0275054 -0.121322 0.110691 -0.0565909 0.0830128 -0.183329 -0.061444 -0.0747519 0.152959 -0.0521887 0.0604665 0.195059 -0.0874432 -0.047488 0.133782 -0.0702829 0.0260803 -0.0315977 0.064439 0.141131 0.15773 0.161103 -0.0551696 0.111177 -0.00221726 -0.124555 0.128203 0.0634426 -0.00487643 -0.0425927</weights>
	</Layer>
</Network>
